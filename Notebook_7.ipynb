{"cells":[{"cell_type":"markdown","metadata":{"id":"UHsNb9UVvtc5"},"source":["# 07 PyTorch Experiment Tracking\n","\n","Machine Learning is very experimental.\n","\n","In order to figure out which ML experiments are worth pursuing, that's where **experiment tracking** comes into play.\n","\n","It helps you figure out what doesn't work and what does work.\n","\n","In this notebook, we're going to see an example of programmatically tracking experiments."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rI0KgNtXvtc8","executionInfo":{"status":"ok","timestamp":1722210556599,"user_tz":-330,"elapsed":6672,"user":{"displayName":"Ashutosh Choudhari","userId":"08732483134051898307"}},"outputId":"1f919229-29d5-4ed1-90e0-6a6b5cbeb040"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.3.1+cu121\n","0.18.1+cu121\n"]}],"source":["import torch\n","import torchvision\n","\n","print(torch.__version__)\n","print(torchvision.__version__)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Evr1yK6Uvtc-","executionInfo":{"status":"ok","timestamp":1722210563108,"user_tz":-330,"elapsed":6514,"user":{"displayName":"Ashutosh Choudhari","userId":"08732483134051898307"}},"outputId":"e507b0f3-0d3f-4f9a-9b01-849b6e544a6a"},"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Couldn't find torchinfo... installing it\n","Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n","Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n","Going modular not found.\n"]}],"source":["# Continue with regular imports\n","import matplotlib.pyplot as plt\n","import torch\n","import torchvision\n","\n","from torch import nn\n","from torchvision import transforms\n","\n","# Try to get torchinfo, install if it doesn't work\n","try:\n","    from torchinfo import summary\n","    print(\"torchinfo imported.\")\n","except:\n","    print(\"[INFO] Couldn't find torchinfo... installing it\")\n","    !pip install torchinfo\n","    from torchinfo import summary\n","\n","# Try to import the going_modular directory, download it from GitHub if it doesn't work\n","try:\n","    from going_modular import data_setup, engine, get_data\n","    print(\"going_modular modules imported successfully.\")\n","except:\n","    # Get the going modular scripts\n","    print(\"Going modular not found.\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"82VHm1Anvtc-","executionInfo":{"status":"ok","timestamp":1722210738209,"user_tz":-330,"elapsed":405,"user":{"displayName":"Ashutosh Choudhari","userId":"08732483134051898307"}},"outputId":"ce40ace5-96df-4cc8-9b19-a5bb9d992669"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cpu'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}],"source":["# Setup device agnostic code\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"mx8vFGH-vtc_","executionInfo":{"status":"ok","timestamp":1722210563108,"user_tz":-330,"elapsed":8,"user":{"displayName":"Ashutosh Choudhari","userId":"08732483134051898307"}}},"outputs":[],"source":["# Set seeds\n","def set_seeds(seed: int=42):\n","    \"\"\"Sets random sets for torch operations.\n","\n","    Args:\n","        seed (int, optional): Random seed to set. Defaults to 42.\n","    \"\"\"\n","    # Set the seed for general torch operations\n","    torch.manual_seed(seed)\n","    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n","    torch.cuda.manual_seed(seed)\n","\n","set_seeds()"]},{"cell_type":"markdown","metadata":{"id":"2QNomw2avtc_"},"source":["## 1. Get data\n","\n","We want to get pizza, steak, sushi images.\n","\n","So we can run experiments building FoodVision Mini and see which model performs the best."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"id":"MRekZdXqvtc_","executionInfo":{"status":"error","timestamp":1722210563108,"user_tz":-330,"elapsed":8,"user":{"displayName":"Ashutosh Choudhari","userId":"08732483134051898307"}},"outputId":"de50975f-0f3c-4240-aaf9-5def94b057a2"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'get_data' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-2dc6f567551f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_dir , test_dir = get_data.download_data(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mraw_url_to_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     )\n","\u001b[0;31mNameError\u001b[0m: name 'get_data' is not defined"]}],"source":["train_dir , test_dir = get_data.download_data(\n","    raw_url_to_dataset=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\"\n","    )"]},{"cell_type":"markdown","metadata":{"id":"ftSKcA4yvtdA"},"source":["## 2. Create Datasets and DataLoaders"]},{"cell_type":"markdown","metadata":{"id":"jDgYlSyDvtdA"},"source":["### 2.1 Create DataLoaders with manual transforms\n","\n","The goal with transforms is to ensure your custom data is formatted in a reproducible way as well as a way that will suit pretrained models."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-kMeUvJMvtdA","executionInfo":{"status":"aborted","timestamp":1722210563108,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ashutosh Choudhari","userId":"08732483134051898307"}}},"outputs":[],"source":["# Setup the directories\n","train_dir, test_dir"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NBQi4_IdvtdB","executionInfo":{"status":"aborted","timestamp":1722210563108,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ashutosh Choudhari","userId":"08732483134051898307"}}},"outputs":[],"source":["# Setup ImagNet normalization levels\n","# See here for documentation: https://pytorch.org/vision/0.12/models.html\n","from torchvision import transforms\n","\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                 std=[0.229, 0.224, 0.225])\n","\n","manual_transform = transforms.Compose([\n","    transforms.Resize(size = (224,224)),\n","    transforms.ToTensor,\n","    normalize\n","])\n","\n","print([f\"Manually created transforms: {manual_transform}\"])\n","\n","# Create DataLoaders\n","from going_modular import data_setup\n","\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n","                                                                               test_dir=test_dir,\n","                                                                               train_transform=manual_transform,\n","                                                                               test_transform=manual_transform,\n","                                                                               batch_size=32,\n","                                                                               num_workers=0)\n","\n","train_dataloader, test_dataloader, class_names"]},{"cell_type":"markdown","metadata":{"id":"zEIMO6gavtdB"},"source":["## 2. Create Datasets and DataLoaders"]},{"cell_type":"markdown","metadata":{"id":"jcW5exbHvtdB"},"source":["### 2.1 Create DataLoaders with manual transforms\n","\n","The goal with transforms is to ensure your custom data is formatted in a reproducible way as well as a way that will suit pretrained models."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MBH9D4mvvtdC","executionInfo":{"status":"aborted","timestamp":1722210563109,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ashutosh Choudhari","userId":"08732483134051898307"}}},"outputs":[],"source":["# Setup the directories\n","train_dir, test_dir"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Byx6QZhkvtdC","executionInfo":{"status":"aborted","timestamp":1722210563109,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ashutosh Choudhari","userId":"08732483134051898307"}}},"outputs":[],"source":["# Setup ImagNet normalization levels\n","# See here for documentation: https://pytorch.org/vision/0.12/models.html\n","from torchvision import transforms\n","\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                 std=[0.229, 0.224, 0.225])\n","\n","manual_transform = transforms.Compose([\n","    transforms.Resize(size = (224,224)),\n","    transforms.ToTensor(),\n","    normalize\n","])\n","\n","print([f\"Manually created transforms: {manual_transform}\"])\n","\n","# Create DataLoaders\n","from going_modular import data_setup\n","\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n","                                                                               test_dir=test_dir,\n","                                                                               train_transform=manual_transform,\n","                                                                               test_transform=manual_transform,\n","                                                                               batch_size=32,\n","                                                                               num_workers=0)\n","\n","train_dataloader, test_dataloader, class_names"]},{"cell_type":"markdown","metadata":{"id":"wY8cYMsZvtdC"},"source":["### 2.2 Creating DataLoaders using automatically created transforms\n","\n","The same principle applies for automatic transforms: we want our custom data in the same format as a pretrained model was trained on."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YcxcFiLKvtdC","executionInfo":{"status":"aborted","timestamp":1722210563109,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ashutosh Choudhari","userId":"08732483134051898307"}}},"outputs":[],"source":["weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # \"DEFAULT\" means best available weights\n","weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OKgbxpqcvtdD","executionInfo":{"status":"aborted","timestamp":1722210563109,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ashutosh Choudhari","userId":"08732483134051898307"}}},"outputs":[],"source":["# Get the transforms used to create our pretrained weights\n","auto_transforms = weights.transforms()\n","auto_transforms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e0ADcmE1vtdD","executionInfo":{"status":"aborted","timestamp":1722210563109,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ashutosh Choudhari","userId":"08732483134051898307"}}},"outputs":[],"source":["# Create DataLoaders using automatic transforms\n","from going_modular import data_setup\n","\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n","    train_dir=train_dir,\n","    test_dir = test_dir,\n","    train_transform=auto_transforms,\n","    test_transform= auto_transforms,\n","    batch_size=32,\n","    num_workers=0\n",")\n","\n","train_dataloader, test_dataloader, class_names"]},{"cell_type":"markdown","metadata":{"id":"UI6aFuhGvtdD"},"source":["## 3. Getting a pretrained model, freeze the base layers and change the classifier head."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iqf4qFyMvtdD","executionInfo":{"status":"aborted","timestamp":1722210563109,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ashutosh Choudhari","userId":"08732483134051898307"}}},"outputs":[],"source":["weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n","\n","model = torchvision.models.efficientnet_b0(weights=weights).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XwY6Qe4lvtdD","executionInfo":{"status":"aborted","timestamp":1722210563109,"user_tz":-330,"elapsed":6,"user":{"displayName":"Ashutosh Choudhari","userId":"08732483134051898307"}}},"outputs":[],"source":["# Print the model information with torchinfo\n","from torchinfo import summary\n","\n","summary(model=model,\n","        input_size=(1,3,224,224),\n","        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n","        col_width=20,\n","        row_settings=[\"var_names\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B88NCU60vtdD","executionInfo":{"status":"aborted","timestamp":1722210563109,"user_tz":-330,"elapsed":6,"user":{"displayName":"Ashutosh Choudhari","userId":"08732483134051898307"}}},"outputs":[],"source":["# Freezing the model\n","for param in model.features.parameters():\n","    param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QTFCZmV3vtdE","outputId":"eb939a10-97d5-430a-aadc-9f0c7773cb4f"},"outputs":[{"data":{"text/plain":["Sequential(\n","  (0): Dropout(p=0.2, inplace=True)\n","  (1): Linear(in_features=1280, out_features=3, bias=True)\n",")"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Updating the classifier head of our model to suit our problem\n","from torch import nn\n","\n","torch.manual_seed(42)\n","torch.cuda.manual_seed(42)\n","model.classifier = nn.Sequential(\n","    nn.Dropout(p=0.2, inplace = True),\n","    nn.Linear(in_features=1280,\n","              out_features=len(class_names))\n",").to(device)\n","\n","model.classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pAD60timvtdE","outputId":"3fc7d1ee-37fb-4bfe-e01d-6469d4f6e8d5"},"outputs":[{"data":{"text/plain":["============================================================================================================================================\n","Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n","============================================================================================================================================\n","EfficientNet (EfficientNet)                                  [1, 3, 224, 224]     [1, 3]               --                   Partial\n","├─Sequential (features)                                      [1, 3, 224, 224]     [1, 1280, 7, 7]      --                   False\n","│    └─Conv2dNormActivation (0)                              [1, 3, 224, 224]     [1, 32, 112, 112]    --                   False\n","│    │    └─Conv2d (0)                                       [1, 3, 224, 224]     [1, 32, 112, 112]    (864)                False\n","│    │    └─BatchNorm2d (1)                                  [1, 32, 112, 112]    [1, 32, 112, 112]    (64)                 False\n","│    │    └─SiLU (2)                                         [1, 32, 112, 112]    [1, 32, 112, 112]    --                   --\n","│    └─Sequential (1)                                        [1, 32, 112, 112]    [1, 16, 112, 112]    --                   False\n","│    │    └─MBConv (0)                                       [1, 32, 112, 112]    [1, 16, 112, 112]    (1,448)              False\n","│    └─Sequential (2)                                        [1, 16, 112, 112]    [1, 24, 56, 56]      --                   False\n","│    │    └─MBConv (0)                                       [1, 16, 112, 112]    [1, 24, 56, 56]      (6,004)              False\n","│    │    └─MBConv (1)                                       [1, 24, 56, 56]      [1, 24, 56, 56]      (10,710)             False\n","│    └─Sequential (3)                                        [1, 24, 56, 56]      [1, 40, 28, 28]      --                   False\n","│    │    └─MBConv (0)                                       [1, 24, 56, 56]      [1, 40, 28, 28]      (15,350)             False\n","│    │    └─MBConv (1)                                       [1, 40, 28, 28]      [1, 40, 28, 28]      (31,290)             False\n","│    └─Sequential (4)                                        [1, 40, 28, 28]      [1, 80, 14, 14]      --                   False\n","│    │    └─MBConv (0)                                       [1, 40, 28, 28]      [1, 80, 14, 14]      (37,130)             False\n","│    │    └─MBConv (1)                                       [1, 80, 14, 14]      [1, 80, 14, 14]      (102,900)            False\n","│    │    └─MBConv (2)                                       [1, 80, 14, 14]      [1, 80, 14, 14]      (102,900)            False\n","│    └─Sequential (5)                                        [1, 80, 14, 14]      [1, 112, 14, 14]     --                   False\n","│    │    └─MBConv (0)                                       [1, 80, 14, 14]      [1, 112, 14, 14]     (126,004)            False\n","│    │    └─MBConv (1)                                       [1, 112, 14, 14]     [1, 112, 14, 14]     (208,572)            False\n","│    │    └─MBConv (2)                                       [1, 112, 14, 14]     [1, 112, 14, 14]     (208,572)            False\n","│    └─Sequential (6)                                        [1, 112, 14, 14]     [1, 192, 7, 7]       --                   False\n","│    │    └─MBConv (0)                                       [1, 112, 14, 14]     [1, 192, 7, 7]       (262,492)            False\n","│    │    └─MBConv (1)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       (587,952)            False\n","│    │    └─MBConv (2)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       (587,952)            False\n","│    │    └─MBConv (3)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       (587,952)            False\n","│    └─Sequential (7)                                        [1, 192, 7, 7]       [1, 320, 7, 7]       --                   False\n","│    │    └─MBConv (0)                                       [1, 192, 7, 7]       [1, 320, 7, 7]       (717,232)            False\n","│    └─Conv2dNormActivation (8)                              [1, 320, 7, 7]       [1, 1280, 7, 7]      --                   False\n","│    │    └─Conv2d (0)                                       [1, 320, 7, 7]       [1, 1280, 7, 7]      (409,600)            False\n","│    │    └─BatchNorm2d (1)                                  [1, 1280, 7, 7]      [1, 1280, 7, 7]      (2,560)              False\n","│    │    └─SiLU (2)                                         [1, 1280, 7, 7]      [1, 1280, 7, 7]      --                   --\n","├─AdaptiveAvgPool2d (avgpool)                                [1, 1280, 7, 7]      [1, 1280, 1, 1]      --                   --\n","├─Sequential (classifier)                                    [1, 1280]            [1, 3]               --                   True\n","│    └─Dropout (0)                                           [1, 1280]            [1, 1280]            --                   --\n","│    └─Linear (1)                                            [1, 1280]            [1, 3]               3,843                True\n","============================================================================================================================================\n","Total params: 4,011,391\n","Trainable params: 3,843\n","Non-trainable params: 4,007,548\n","Total mult-adds (M): 384.59\n","============================================================================================================================================\n","Input size (MB): 0.60\n","Forward/backward pass size (MB): 107.88\n","Params size (MB): 16.05\n","Estimated Total Size (MB): 124.53\n","============================================================================================================================================"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["summary(model=model,\n","        input_size=(1,3,224,224),\n","        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n","        col_width=20,\n","        row_settings=[\"var_names\"])"]},{"cell_type":"markdown","metadata":{"id":"Y4oSJDzhvtdE"},"source":["## 4. Train a single model and track results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aZvmoYmYvtdE"},"outputs":[],"source":["# Define the loss_fn and optimizer\n","loss_fn = nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.Adam(params=model.parameters(),\n","                             lr = 0.001)"]},{"cell_type":"markdown","metadata":{"id":"Tp_qPogdvtdE"},"source":["To track experiments, we're going to bee using TensorBoard: https://www.tensorflow.org/tensorboard/\n","\n","And to imteract with TensorBoard, we can use PyTorch's SummaryWriter: https://pytorch.org/docs/stable/tensorboard.html\n","\n","* Also, see here: https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uuzXYC6QvtdE","outputId":"3a230066-1d14-4907-b091-e167551f7ba0"},"outputs":[{"data":{"text/plain":["<torch.utils.tensorboard.writer.SummaryWriter at 0x188eec18790>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# Setup a SummaryWriter\n","from torch.utils.tensorboard import SummaryWriter\n","writer = SummaryWriter(log_dir='runs')\n","writer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"33EUbfgLvtdE"},"outputs":[],"source":["from going_modular.engine import train_step, test_step\n","\n","from typing import Dict, List, Tuple\n","import torch\n","from tqdm.auto import tqdm\n","\n","def train(model: torch.nn.Module,\n","          train_dataloader: torch.utils.data.DataLoader,\n","          test_dataloader: torch.utils.data.DataLoader,\n","          optimizer: torch.optim.Optimizer,\n","          loss_fn: torch.nn.Module,\n","          epochs: int,\n","          device: torch.device) -> Dict[str, List[float]]:\n","    \"\"\"Trains and tests a PyTorch model.\n","\n","    Passes a target PyTorch models through train_step() and test_step()\n","    functions for a number of epochs, training and testing the model\n","    in the same epoch loop.\n","\n","    Calculates, prints and stores evaluation metrics throughout.\n","\n","    Args:\n","      model: A PyTorch model to be trained and tested.\n","      train_dataloader: A DataLoader instance for the model to be trained on.\n","      test_dataloader: A DataLoader instance for the model to be tested on.\n","      optimizer: A PyTorch optimizer to help minimize the loss function.\n","      loss_fn: A PyTorch loss function to calculate loss on both datasets.\n","      epochs: An integer indicating how many epochs to train for.\n","      device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","    Returns:\n","      A dictionary of training and testing loss as well as training and\n","      testing accuracy metrics. Each metric has a value in a list for\n","      each epoch.\n","      In the form: {train_loss: [...],\n","                    train_acc: [...],\n","                    test_loss: [...],\n","                    test_acc: [...]}\n","      For example if training for epochs=2:\n","                  {train_loss: [2.0616, 1.0537],\n","                    train_acc: [0.3945, 0.3945],\n","                    test_loss: [1.2641, 1.5706],\n","                    test_acc: [0.3400, 0.2973]}\n","    \"\"\"\n","    # Create empty results dictionary\n","    results = {\"train_loss\": [],\n","        \"train_acc\": [],\n","        \"test_loss\": [],\n","        \"test_acc\": []\n","    }\n","\n","    # Loop through training and testing steps for a number of epochs\n","    for epoch in tqdm(range(epochs)):\n","        train_loss, train_acc = train_step(model=model,\n","                                            dataloader=train_dataloader,\n","                                            loss_fn=loss_fn,\n","                                            optimizer=optimizer,\n","                                            device=device)\n","        test_loss, test_acc = test_step(model=model,\n","            dataloader=test_dataloader,\n","            loss_fn=loss_fn,\n","            device=device)\n","\n","        # Print out what's happening\n","        print(\n","            f\"Epoch: {epoch+1} | \"\n","            f\"train_loss: {train_loss:.4f} | \"\n","            f\"train_acc: {train_acc:.4f} | \"\n","            f\"test_loss: {test_loss:.4f} | \"\n","            f\"test_acc: {test_acc:.4f}\"\n","        )\n","\n","        # Update results dictionary\n","        results[\"train_loss\"].append(train_loss)\n","        results[\"train_acc\"].append(train_acc)\n","        results[\"test_loss\"].append(test_loss)\n","        results[\"test_acc\"].append(test_acc)\n","\n","        ### New: Experiment tracking ###\n","        writer.add_scalars(main_tag = \"Loss\",\n","                           tag_scalar_dict = {\"train_loss\":train_loss,\n","                                              \"test_loss\":test_loss},\n","                           global_step = epoch)\n","\n","        writer.add_scalars(main_tag = \"Accuracy\",\n","                           tag_scalar_dict = {\"train_acc\":train_acc,\n","                                              \"test_acc\" :test_acc},\n","                           global_step = epoch)\n","\n","        writer.add_graph(model=model,\n","                         input_to_model = torch.randn(32,3,224,224).to(device))\n","\n","        # Close the writer\n","        writer.close()\n","        ### End New ###\n","\n","    # Return the filled results at the end of the epochs\n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rcjqBQq-vtdF","outputId":"48ee0518-eb6a-4e30-addc-476d610045ca"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/25 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1 | train_loss: 0.2516 | train_acc: 0.9727 | test_loss: 0.3690 | test_acc: 0.8561\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 1/25 [00:07<03:00,  7.52s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2 | train_loss: 0.3598 | train_acc: 0.8320 | test_loss: 0.4157 | test_acc: 0.8456\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 2/25 [00:15<03:02,  7.93s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3 | train_loss: 0.3332 | train_acc: 0.8516 | test_loss: 0.3752 | test_acc: 0.8665\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 3/25 [00:24<03:00,  8.22s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4 | train_loss: 0.2891 | train_acc: 0.9727 | test_loss: 0.3662 | test_acc: 0.8665\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 4/25 [00:32<02:52,  8.24s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5 | train_loss: 0.3146 | train_acc: 0.8359 | test_loss: 0.4046 | test_acc: 0.8769\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 5/25 [00:41<02:50,  8.52s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 6 | train_loss: 0.2657 | train_acc: 0.9609 | test_loss: 0.3725 | test_acc: 0.8665\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 6/25 [00:51<02:51,  9.03s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 7 | train_loss: 0.2553 | train_acc: 0.9688 | test_loss: 0.3585 | test_acc: 0.8769\n"]},{"name":"stderr","output_type":"stream","text":[" 28%|██▊       | 7/25 [01:00<02:39,  8.87s/it]"]}],"source":["# Train model\n","# Note: not using engine.py or engine.train() funtion above\n","\n","set_seeds()\n","results = train(model=model,\n","train_dataloader = train_dataloader,\n","test_dataloader = test_dataloader,\n","optimizer = optimizer,\n","loss_fn = loss_fn,\n","epochs = 25,\n","device = device)"]},{"cell_type":"markdown","metadata":{"id":"sMvml-HNvtdF"},"source":["## 5. View our model's results with TensorBoard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-uUivWbAvtdF","outputId":"008960bd-6353-4002-f605-91958f97ddd0"},"outputs":[{"data":{"text/html":["\n","      <iframe id=\"tensorboard-frame-7298242cfa889e63\" width=\"100%\" height=\"800\" frameborder=\"0\">\n","      </iframe>\n","      <script>\n","        (function() {\n","          const frame = document.getElementById(\"tensorboard-frame-7298242cfa889e63\");\n","          const url = new URL(\"/\", window.location);\n","          const port = 6006;\n","          if (port) {\n","            url.port = port;\n","          }\n","          frame.src = url;\n","        })();\n","      </script>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Let's view our expreiments from within the notebook\n","%load_ext tensorboard\n","#%reload_ext tensorboard\n","%tensorboard --logdir runs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B9dX1oQgvtdG"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"AR","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}